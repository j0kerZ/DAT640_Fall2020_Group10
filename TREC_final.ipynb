{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cbor in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\phamb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trec-car-tools in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from trec-car-tools) (1.17.4)\n",
      "Requirement already satisfied: cbor>=1.0.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from trec-car-tools) (1.0.0)\n",
      "Requirement already satisfied: typing>=3.6.2 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from trec-car-tools) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\phamb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp37-cp37m-win_amd64.whl (342.5 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (1.17.4)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (42.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.23)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (8.0.0)\n",
      "Installing collected packages: tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\phamb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python37\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
      "\n",
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\phamb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-serving-server in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (1.10.0)\n",
      "Requirement already satisfied: GPUtil>=1.3.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-server) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-server) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-server) (1.17.4)\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-server) (20.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-server) (1.13.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\phamb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-serving-client in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-client) (1.17.4)\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in c:\\users\\phamb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from bert-serving-client) (20.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\phamb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install cbor\n",
    "!pip install trec-car-tools\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from tqdm import tqdm\n",
    "from trec_car.read_data import *\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Elasticsearch\n",
    "es = Elasticsearch()\n",
    "# Init sentence to BERT vector transformer\n",
    "st = SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECCAR_FILE = '../dedup.articles-paragraphs.cbor'\n",
    "MARCO_FILE = '../collection.tsv'\n",
    "MARCO_DUP_FILE = '../duplicate_list_v1.0.txt'\n",
    "INDEX = 'trec_index'\n",
    "FIELD = ['body']\n",
    "BULK_LEN = 5000\n",
    "\n",
    "INDEX_SETTINGS = {\n",
    "    'mappings': {\n",
    "            'properties': {\n",
    "                'body': {\n",
    "                    'type': 'text',\n",
    "                    'term_vector': 'yes',\n",
    "                    'analyzer': 'english'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'trec_index'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if es.indices.exists(INDEX):\n",
    "    es.indices.delete(INDEX)\n",
    "    \n",
    "es.indices.create(index=INDEX, body=INDEX_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_bulk(bulk_data, doc, doc_id):\n",
    "    data = {\n",
    "        \"_index\": INDEX,\n",
    "        \"_id\": doc_id,\n",
    "        \"body\": doc\n",
    "    }\n",
    "    bulk_data.append(data)\n",
    "    return bulk_data\n",
    "\n",
    "def start_bulk(es, bulk_data):\n",
    "    helpers.bulk(es, bulk_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files & Indexing\n",
    "<br>\n",
    "\n",
    "### TREC CAR paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing TREC CAR: 29794697it [2:14:20, 3696.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed total 29794697 docs\n",
      "With 0 errors\n"
     ]
    }
   ],
   "source": [
    "with open(TRECCAR_FILE, 'rb') as datafile:\n",
    "    c = 0\n",
    "    e = 0\n",
    "    bulk_data = []\n",
    "    for p in tqdm(iter_paragraphs(datafile), desc=\"Indexing TREC CAR\", position=0, leave=True):\n",
    "        try:\n",
    "            # PARAGRAPH ID\n",
    "            doc_id = \"CAR_\" + p.para_id\n",
    "            \n",
    "            # PARAGRAPH TEXT\n",
    "            texts = [elem.text if isinstance(elem, ParaText)\n",
    "                     else elem.anchor_text\n",
    "                     for elem in p.bodies]\n",
    "            doc = ' '.join(texts)\n",
    "            \n",
    "            c +=1 \n",
    "            add_to_bulk(bulk_data, doc, doc_id)\n",
    "            if len(bulk_data) >= BULK_LEN:\n",
    "                start_bulk(es, bulk_data)\n",
    "                bulk_data = []\n",
    "\n",
    "        except Exception as E:\n",
    "            e +=1\n",
    "\n",
    "    if len(bulk_data) > 0:\n",
    "        start_bulk(es, bulk_data)\n",
    "\n",
    "print('Indexed total {} docs'.format(c))\n",
    "print('With {} errors'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS MARCO collection\n",
    "<br>\n",
    "\n",
    "#### Load duplication file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_dict = {}\n",
    "duplines = open(MARCO_DUP_FILE).readlines()\n",
    "for line in duplines:\n",
    "    data = line.strip().split(':')\n",
    "    if len(data[1]) > 0:\n",
    "        dups = data[-1].split(',')\n",
    "        for dup in dups:\n",
    "            dup_dict[dup] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index MARCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing MS MARCO: 8841823it [25:37, 5750.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed total 8635155 docs\n",
      "With 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(MARCO_FILE, 'r', encoding=\"utf-8\") as datafile:\n",
    "    c = 0\n",
    "    e = 0\n",
    "    bulk_data = []\n",
    "    for line in tqdm(datafile, desc=\"Indexing MS MARCO\", position=0, leave=True):\n",
    "        \n",
    "        try:\n",
    "            # ID & TEXT\n",
    "            doc_id, doc = line.strip().split('\\t', 1)\n",
    "            doc_id = 'MARCO_' + doc_id\n",
    "            \n",
    "            if doc_id in dup_dict:\n",
    "                continue\n",
    "            \n",
    "            c +=1 \n",
    "            add_to_bulk(bulk_data, doc, doc_id)\n",
    "            if len(bulk_data) >= BULK_LEN:\n",
    "                start_bulk(es, bulk_data)\n",
    "                bulk_data = []\n",
    "            \n",
    "        except Exception as E:\n",
    "            e +=1\n",
    "            \n",
    "    if len(bulk_data) > 0:\n",
    "        start_bulk(es, bulk_data)\n",
    "        \n",
    "print('Indexed total {} docs'.format(c))\n",
    "print('With {} errors'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries - QREL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=r'treccastweb\\2019\\data\\training\\train_topics_v1.0.txt'\n",
    "qrel=r'treccastweb\\2019\\data\\training\\train_topics_mod.qrel'\n",
    "test_doc=r'treccastweb\\2020\\2020_manual_evaluation_topics_v1.0.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load evaluation queries and the ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(filepath):\n",
    "    q_id=0\n",
    "    queries = {}\n",
    "    qrels = {}\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for data in json.load(f):\n",
    "            for quer in (data['turn']):\n",
    "                q_id=(str(data['number'])+'_'+str(quer['number']))\n",
    "                queries[q_id]=(quer['raw_utterance'])\n",
    "                for k,v in quer.items():\n",
    "                    if 'canonical_result_id' in k:\n",
    "                        qrels[q_id]=v\n",
    "\n",
    "    return (qrels, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Training Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(filepath):\n",
    "    queries = {}\n",
    "    \n",
    "    query_ID=''\n",
    "    doc_num=0      \n",
    "    with open( filepath ,\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            sp_line=line.split(':')\n",
    "            if sp_line[0] =='Number':                \n",
    "                doc_num=sp_line[1].strip()               \n",
    "            \n",
    "            check_dig=line[0:2].strip()\n",
    "            if check_dig.isdigit() :\n",
    "                    query_ID=doc_num+'_'+check_dig                    \n",
    "                    queries[query_ID]=line.replace(line[0:2],'').strip()\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Training QRELs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(filepath):\n",
    "    qrels = defaultdict(list)\n",
    "        \n",
    "    with open( filepath ,\"rt\", encoding='latin-1') as fin:\n",
    "        for line in fin.readlines():\n",
    "            line_split=line.split(' ') \n",
    "            qrels[line_split[0]].append(line_split[2])\n",
    "\n",
    "    return qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning-to-rank model\n",
    "<br>\n",
    "\n",
    "## Load files for Learning-to-rank model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(es, query, field='body', index='trec_index'):\n",
    "    tokens = es.indices.analyze(index=index, body={'text': query})['tokens']\n",
    "    query_terms = []\n",
    "    for t in sorted(tokens, key=lambda x: x['position']):\n",
    "        hits = es.search(index=index, body={'query': {'match': {field: t['token']}}}, \n",
    "                                   _source=False, size=1).get('hits', {}).get('hits', {})\n",
    "        doc_id = hits[0]['_id'] if len(hits) > 0 else None\n",
    "        if doc_id is None:\n",
    "            continue\n",
    "        query_terms.append(t['token'])\n",
    "    return query_terms\n",
    "\n",
    "def get_doc_term_freqs(es, doc_id, field='body', index='trec_index'):\n",
    "    tv = es.termvectors(index=index, id=doc_id, fields=field, term_statistics=True)\n",
    "    if tv['_id'] != doc_id:\n",
    "        return None\n",
    "    if field not in tv['term_vectors']:\n",
    "        return None\n",
    "    term_freqs = {}\n",
    "    for term, term_stat in tv['term_vectors'][field]['terms'].items():\n",
    "        term_freqs[term] = term_stat['term_freq']\n",
    "    return term_freqs\n",
    "        \n",
    "def get_query_term_freqs(es, query_terms):\n",
    "    c = Counter()\n",
    "    for term in query_terms:\n",
    "        c[term] += 1\n",
    "    return dict(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Query Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_query_features(query_terms, es, index='trec_index'):\n",
    "    q_features = {}\n",
    "    q_features['query_length']=(len(query_terms))\n",
    "        \n",
    "    idf=[]\n",
    "    es.indices.refresh(index)\n",
    "    N=(es.count(index=index)['count'])\n",
    "    for q in query_terms:\n",
    "        n=(es.count(index=index,q='body:'+q)['count'])\n",
    "        try:\n",
    "            idf.append(math.log(N/n))\n",
    "        except ZeroDivisionError:\n",
    "            idf.append(0) \n",
    "            \n",
    "    q_features[\"query_sum_idf\"] = sum(idf) if len(idf) > 0 else 0\n",
    "    q_features[\"query_max_idf\"] = max(idf) if len(idf) > 0 else 0\n",
    "    q_features[\"query_avg_idf\"] = q_features[\"query_sum_idf\"] / len(idf) if len(idf) > 0 else 0\n",
    "        \n",
    "    return q_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract document features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc_features(doc_id, es, index='trec_index'):\n",
    "    doc_features = {}\n",
    "\n",
    "    termvectors = es.termvectors(index=index, id=doc_id, fields=\"body\")[\"term_vectors\"]\n",
    "    if termvectors:\n",
    "        val = 0\n",
    "        for key, value in termvectors['body'][\"terms\"].items():\n",
    "            val += value[\"term_freq\"]\n",
    "        doc_features[\"doc_length\"] = val\n",
    "\n",
    "    return doc_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Query-Document features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_query_doc_features(query_terms, doc_id, es, index='trec_index'):\n",
    "    q_doc_features = {}\n",
    "\n",
    "    b=[]\n",
    "    tf_bod = []\n",
    "    \n",
    "    for q in query_terms:\n",
    "        q_t={}\n",
    "        dtf=get_doc_term_freqs(es, doc_id, 'body', index=index)\n",
    "        if dtf and q in dtf:\n",
    "            b.append(q)\n",
    "            tf_bod.append(dtf[q])\n",
    "        else:\n",
    "            tf_bod.append(0)\n",
    "\n",
    "    q_doc_features['sum_TF_body']=sum(tf_bod) if len(tf_bod) > 0 else 0\n",
    "    q_doc_features['max_TF_body']=max(tf_bod) if len(tf_bod) > 0 else 0\n",
    "    q_doc_features['avg_TF_body']=np.mean(tf_bod) if len(tf_bod) > 0 else 0\n",
    "\n",
    "    q_doc_features['unique_query_terms_in_body'] = len(set(b)) if len(b) > 0 else 0\n",
    "\n",
    "    return q_doc_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and combine all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_QUERY = ['query_length', 'query_sum_idf', 'query_max_idf', 'query_avg_idf']\n",
    "FEATURES_DOC = ['doc_length']\n",
    "FEATURES_QUERY_DOC = ['unique_query_terms_in_body', 'sum_TF_body', 'max_TF_body', 'avg_TF_body']\n",
    "\n",
    "def extract_features(query_terms, doc_id, es, index='trec_index'):\n",
    "    feature_vect = []\n",
    "    \n",
    "    query_features = extract_query_features(query_terms, es, index=index)\n",
    "    for f in FEATURES_QUERY:\n",
    "        feature_vect.append(query_features[f])\n",
    "    \n",
    "    doc_features = extract_doc_features(doc_id, es, index=index)\n",
    "    for f in FEATURES_DOC:\n",
    "        feature_vect.append(doc_features[f])\n",
    "\n",
    "    query_doc_features = extract_query_doc_features(query_terms, doc_id, es, index=index)\n",
    "    for f in FEATURES_QUERY_DOC:\n",
    "        feature_vect.append(query_doc_features[f])\n",
    "\n",
    "    return feature_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ltr_training_data(query_ids, es, index='trec_index'):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for qid in query_ids:\n",
    "        query = TREC_QUERIES[qid]\n",
    "        q = analyze_query(es, query, \"body\", index=index)\n",
    "        for doc_id in TREC_QRELS[qid]:\n",
    "            if (es.termvectors(index=INDEX, id=doc_id)['found']) != False:\n",
    "                X.append(extract_features(q, doc_id, es, index=index))\n",
    "                y.append(1)\n",
    "            else:\n",
    "                continue\n",
    "        search = es.search(index=index, q=\" \".join(q), _source=True, size=100)[\"hits\"][\"hits\"]\n",
    "        for det in search:\n",
    "            doc_id = det[\"_id\"]\n",
    "            if doc_id in TREC_QRELS[qid]: continue\n",
    "            X.append(extract_features(q, doc_id, es, index=index))\n",
    "            y.append(0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWiseLTRModel(object):\n",
    "    def __init__(self, regressor):\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def _train(self, X, y):\n",
    "        assert self.regressor is not None\n",
    "        self.model = self.regressor.fit(X, y)\n",
    "\n",
    "    def rank(self, ft, doc_ids):\n",
    "        assert self.model is not None\n",
    "        rel_labels = self.model.predict(ft)\n",
    "        sort_indices = np.argsort(rel_labels)[::-1]\n",
    "\n",
    "        results = []\n",
    "        for i in sort_indices:\n",
    "            results.append((doc_ids[i], rel_labels[i]))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the rankings of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings(ltr, query_ids, es, index='trec_index', rerank=False):\n",
    "    test_rankings = {}\n",
    "    for i, query_id in enumerate(query_ids):\n",
    "        query_terms = analyze_query(es, TEST_QUERIES[query_id], 'body', index=index)\n",
    "        if len(query_terms) == 0:\n",
    "            continue\n",
    "        hits = es.search(index=index, q=' '.join(query_terms), _source=True, size=100)['hits']['hits']        \n",
    "        test_rankings[query_id] = [hit['_id'] for hit in hits]\n",
    "        \n",
    "        feat={}\n",
    "        if rerank:\n",
    "            for doc_id in (test_rankings[query_id]):\n",
    "                feat[doc_id]=(extract_features(query_terms, doc_id, es, index=index))\n",
    "            rel=(ltr.rank(list(feat.values()), list(feat.keys())))\n",
    "            ranks=sorted(rel, key = lambda x: x[1], reverse=True)\n",
    "            test_rankings[query_id]=[k for k,v in ranks]\n",
    "    return test_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "<br>\n",
    "\n",
    "## Combine with to learning-to-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_vector(query):\n",
    "    return st.encode([query])[0]\n",
    "\n",
    "def prepare_BERT_training_data(query_ids, es, index='trec_index'):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for qid in query_ids:\n",
    "        query = TREC_QUERIES[qid]\n",
    "        q = analyze_query(es, query, \"body\", index=index)\n",
    "        for doc_id in TREC_QRELS[qid]:\n",
    "            if (es.termvectors(index=INDEX, id=doc_id)['found']) != False:\n",
    "                doc = es.get(index, doc_id, source=True)['_source']['body']\n",
    "                X.append(BERT_vector(doc))\n",
    "                y.append(1)\n",
    "            else:\n",
    "                continue\n",
    "        search = es.search(index=index, q=\" \".join(q), _source=True, size=100)[\"hits\"][\"hits\"]\n",
    "        for det in search:\n",
    "            doc_id = det[\"_id\"]\n",
    "            if doc_id in TREC_QRELS[qid]: continue\n",
    "            X.append(BERT_vector(det['_source']['body']))\n",
    "            y.append(0)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def BERT_rankings(ltr, query_ids, es, index='trec_index'):\n",
    "    test_rankings = {}\n",
    "    for i, query_id in enumerate(query_ids):\n",
    "        query_terms = analyze_query(es, TEST_QUERIES[query_id], 'body', index=index)\n",
    "        if len(query_terms) == 0:\n",
    "            continue\n",
    "        hits = es.search(index=index, q=' '.join(query_terms), _source=True, size=100)['hits']['hits']        \n",
    "        test_rankings[query_id] = []\n",
    "        docs = {}\n",
    "        for hit in hits:\n",
    "            test_rankings[query_id].append(hit['_id'])\n",
    "            docs[hit['_id']] = (hit['_source']['body'])\n",
    "        \n",
    "        feat={}\n",
    "        for doc_id in (test_rankings[query_id]):\n",
    "            feat[doc_id]=(BERT_vector(docs[doc_id]))\n",
    "        rel=(ltr.rank(list(feat.values()), list(feat.keys())))\n",
    "        ranks=sorted(rel, key = lambda x: x[1], reverse=True)\n",
    "        test_rankings[query_id]=[k for k,v in ranks]\n",
    "    return test_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim_BERT_ranking(query_ids, es, index='trec_index'):\n",
    "    test_rankings = {}\n",
    "    for i, query_id in enumerate(query_ids):\n",
    "        query_terms = analyze_query(es, TEST_QUERIES[query_id], 'body', index=index)\n",
    "        if len(query_terms) == 0:\n",
    "            continue\n",
    "        query_vec = BERT_vector(' '.join(query_terms))\n",
    "        hits = es.search(index=index, q=' '.join(query_terms), _source=True, size=100)['hits']['hits']        \n",
    "        \n",
    "        rel = []\n",
    "        test_rankings[query_id] = []\n",
    "        for hit in hits:\n",
    "            test_rankings[query_id].append(hit['_id'])\n",
    "            doc_BERT = BERT_vector(hit['_source']['body'])\n",
    "            cos_scores = util.pytorch_cos_sim(query_vec, doc_BERT)\n",
    "            rel.append((hit['_id'], cos_scores[0][0].item()))\n",
    "        \n",
    "        ranks=sorted(rel, key = lambda x: x[1], reverse=True)\n",
    "        test_rankings[query_id]=[k for k,v in ranks]\n",
    "    return test_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 184\n"
     ]
    }
   ],
   "source": [
    "def get_reciprocal_rank(system_ranking, ground_truth):\n",
    "    for i, doc_id in enumerate(system_ranking):\n",
    "        if doc_id in ground_truth:\n",
    "            return 1 / (i + 1)\n",
    "    return 0\n",
    "    \n",
    "def get_mean_eval_measure(system_rankings, ground_truth, eval_function):\n",
    "\n",
    "    sum_score = 0\n",
    "    for query_id, system_ranking in system_rankings.items():\n",
    "        sum_score += eval_function(system_ranking, ground_truth[query_id])\n",
    "    return sum_score / len(system_rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Queries variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training Queries and QRELs\n",
    "TREC_QRELS=load_qrels(qrel)\n",
    "TREC_QUERIES=load_queries(txt)\n",
    "\n",
    "# Get testing Queries and QRELs\n",
    "TEST_QRELS, TEST_QUERIES = make_test(test_doc)\n",
    "\n",
    "random.seed(a=1234567)\n",
    "trec_query_ids = sorted(list(TREC_QUERIES.keys()))\n",
    "random.shuffle(trec_query_ids)\n",
    "TRAIN_QUERY_IDS = trec_query_ids\n",
    "TEST_QUERY_IDS = TEST_QUERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Retreival model\n",
    "<br>\n",
    "\n",
    "## BM25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_BM25 = get_rankings(None, test_query_ids, es, index=INDEX, rerank=False)\n",
    "mrr_BM25 = get_mean_eval_measure(rankings_BM25, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-to-rank using normal feature extraction\n",
    "<br>\n",
    "\n",
    "### Prepare the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_ltr_training_data(TRAIN_QUERY_IDS, es, index=INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestRegressor(max_depth=15, random_state=0, n_estimators=10)\n",
    "ltr1 = PointWiseLTRModel(clf1)\n",
    "ltr1._train(X_train, y_train)\n",
    "rankings_ltr1 = get_rankings(ltr1, test_query_ids, es, index=INDEX, rerank=True)\n",
    "mrr_ltr1 = get_mean_eval_measure(rankings_ltr1, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MLPRegressor(random_state=0, max_iter=1500)\n",
    "ltr2 = PointWiseLTRModel(clf2)\n",
    "ltr2._train(X_train, y_train)\n",
    "rankings_ltr2 = get_rankings(ltr2, test_query_ids, es, index=INDEX, rerank=True)\n",
    "mrr_ltr2 = get_mean_eval_measure(rankings_ltr2, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=10, random_state=0)\n",
    "ltr3 = PointWiseLTRModel(clf3)\n",
    "ltr3._train(X_train, y_train)\n",
    "rankings_ltr3 = get_rankings(ltr3, test_query_ids, es, index=INDEX, rerank=True)\n",
    "mrr_ltr3 = get_mean_eval_measure(rankings_ltr3, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-to-rank using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_BERT_training_data(TRAIN_QUERY_IDS, es, index=INDEX)\n",
    "\n",
    "clfb = MLPRegressor(max_depth=5, random_state=0, n_estimators=10)\n",
    "ltrb = PointWiseLTRModel(clfb)\n",
    "ltrb._train(X_train, y_train)\n",
    "rankings_ltr_Bert = BERT_rankings(ltrb, TEST_QUERY_IDS, es, index=INDEX)\n",
    "mrr_ltr_Bert = get_mean_eval_measure(rankings_ltr_Bert, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_BERT = cossim_BERT_ranking(TEST_QUERY_IDS, es, index=INDEX)\n",
    "mrr_BERT = get_mean_eval_measure(ranking_BERT, TEST_QRELS, get_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['First-pass(BM25)','RandomForestRegressor','MLPRegressor','GradientBoostingClassifier', 'BERT']\n",
    "pd.DataFrame([mrr_first_pass,mrr_ltr1,mrr_ltr2,mrr_ltr3, mmr_BERT],index=models,columns=['MRR Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 188\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "def get_plot_data(system_rankings, ground_truth, eval_function):\n",
    "    s=0\n",
    "    data = []\n",
    "    for query_id, system_ranking in system_rankings.items():\n",
    "        rr = eval_function(system_ranking, ground_truth[query_id])\n",
    "        if rr > 0:\n",
    "            s += 1\n",
    "        data.append(rr)\n",
    "    return data\n",
    "\n",
    "BERT_plot = get_plot_data(ranking_BERT, TEST_QRELS, get_reciprocal_rank)\n",
    "\n",
    "plot.plot(BERT_plot, 'ro')\n",
    "plot.axhline(mrr_BERT, color='k', linestyle='dashed', linewidth=1)\n",
    "plot.title('BERT with cosine similarity')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
